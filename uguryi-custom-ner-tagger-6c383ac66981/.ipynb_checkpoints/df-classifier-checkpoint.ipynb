{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last updated: 2019-03-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload DF corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Way #1 (not preferred)\n",
    "\n",
    "Manually upload a zip file of 2017 documents and then unzip it. \n",
    "\n",
    "It takes a couple of minutes to upload the whole thing.\n",
    "\n",
    "Notes:\n",
    "- A residue folder `__MACOSX` is created when unzipping; not sure why...\n",
    "- The following error is encountered when unzipping (maybe related to above?):\n",
    "\n",
    "```\n",
    "IOPub data rate exceeded.\n",
    "The notebook server will temporarily stop sending output\n",
    "to the client in order to avoid crashing it.\n",
    "To change this limit, set the config variable\n",
    "`--NotebookApp.iopub_data_rate_limit`.\n",
    "\n",
    "Current values:\n",
    "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
    "NotebookApp.rate_limit_window=3.0 (secs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip DocumentsParsed-2017.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Way #2 (better)\n",
    "\n",
    "Create a new directory `df-corpus` and copy the whole corpus from `S3` into this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir df-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 cp s3://tagworks.thusly.co/decidingforce/corpus/ ./df-corpus --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!find df-corpus/* -maxdepth 0 -type d | wc -l # See how many folders are under df-corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Stanford CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!unzip stanford-corenlp-full-2018-10-05.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload prop file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df-classifier.prop` tells the CRF classifier \"how\" to go about classifying. NER Feature Factory lists all the possible parameters that can be tuned: https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/ie/NERFeatureFactory.html\n",
    "\n",
    "Right now I'm manually uploading it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download stopwords and wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a few seconds to load..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json, nltk, os, re, string\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_annotations(path_to_data):\n",
    "    with gzip.open(os.path.join(path_to_data, \"annotations.json.gz\"), \n",
    "                   mode='rt', \n",
    "                   encoding='utf8') as unzipped: \n",
    "        annotations = json.load(unzipped)\n",
    "    return(annotations)\n",
    "\n",
    "def store_text(path_to_data):\n",
    "    with gzip.open(os.path.join(path_to_data, \"text.txt.gz\"), \n",
    "                   mode='rt', \n",
    "                   encoding='utf8') as unzipped: \n",
    "        text = unzipped.read()\n",
    "    return(text)\n",
    "\n",
    "def gen_lst_tags(annotations):\n",
    "    lst_tagged_text = []\n",
    "    for e1 in annotations[\"tuas\"]:\n",
    "        for e2 in annotations[\"tuas\"][e1]:\n",
    "            for e3 in annotations[\"tuas\"][e1][e2]:\n",
    "                lst_tagged_text += [[e1, e3[0], e3[1], e3[2]]]\n",
    "    lst_tagged_text = sorted(lst_tagged_text, key = lambda x: x[1])\n",
    "    return(lst_tagged_text)\n",
    "\n",
    "def reorganize_tag_positions(tag_positions):\n",
    "    keep_going = 1\n",
    "    while keep_going:\n",
    "        keep_going = 0\n",
    "        p = 0\n",
    "        tag_positions_better = []\n",
    "        while p < len(tag_positions) - 1:\n",
    "            if tag_positions[p][1] < tag_positions[p+1][0] - 1:\n",
    "                tag_positions_better += [tag_positions[p]]\n",
    "                p += 1\n",
    "                if p == len(tag_positions) - 1:\n",
    "                    tag_positions_better += [tag_positions[p]]\n",
    "            elif tag_positions[p][1] >= tag_positions[p+1][1]:\n",
    "                tag_positions_better += [tag_positions[p]]\n",
    "                p += 2\n",
    "                keep_going = 1\n",
    "                if p == len(tag_positions) - 1:\n",
    "                    tag_positions_better += [tag_positions[p]]\n",
    "            else:\n",
    "                tag_positions_better += [[tag_positions[p][0], tag_positions[p+1][1]]]\n",
    "                p += 2\n",
    "                keep_going = 1\n",
    "                if p == len(tag_positions) - 1:\n",
    "                    tag_positions_better += [tag_positions[p]]\n",
    "        tag_positions = tag_positions_better.copy()\n",
    "    return(tag_positions_better)\n",
    "\n",
    "def gen_lst_untagged(tag_positions_better, text):\n",
    "    lst_untagged_text = []\n",
    "    p0 = 0\n",
    "    for p in tag_positions_better:\n",
    "        #lst_untagged_text += [['Untagged', p0, p[0]-1, text[p0:p[0]]]]\n",
    "        lst_untagged_text += [['O', p0, p[0]-1, text[p0:p[0]]]]\n",
    "        p0 = p[1] + 1\n",
    "    lst_untagged_text = [e for e in lst_untagged_text]\n",
    "    return(lst_untagged_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `gen_word_tag_lst`\n",
    "\n",
    "This function allows users to specify whether to:\n",
    "\n",
    "- remove stopwords or not\n",
    "- use POS tags or not\n",
    "- focus on one label and treat everything else as other (e.g., Protester vs. O) or not\n",
    "    - in other words, binary classification vs. multiclass classification\n",
    "\n",
    "It is possible to add more flexibility to this function to also allow users to specificy whether to:\n",
    "\n",
    "- remove punctuation or not (removing punctuation is default right now)\n",
    "- transform words to lowercase or not (transforming to lowercase is default right now)\n",
    "- lemmatize words or not (lemmatizing is default right now)\n",
    "\n",
    "##### `write_to_tsv`\n",
    "\n",
    "This function allows users to specify which set of documents to use for the train and test datasets. The `tsv` file generated at the end includes words from documents between `start_index` and `end_index`. `end_index` can be as high as the number of documents in the corpus (here, 8094). The function needs to be run twice, once for generating the train dataset and once for generating the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_word_tag_lst(path_to_data, remove_stop_words, use_pos, focus, focus_word):\n",
    "    \n",
    "    # Store annotations\n",
    "    annotations = store_annotations(path_to_data)\n",
    "\n",
    "    # Store full text\n",
    "    text = store_text(path_to_data)\n",
    "    \n",
    "    # Generate list of tagged text\n",
    "    lst_tagged_text = gen_lst_tags(annotations)\n",
    "    \n",
    "    # Generate list of tag positions\n",
    "    tag_positions = sorted([e[1:3] for e in lst_tagged_text])\n",
    "    \n",
    "    # Reorganize tag positions\n",
    "    tag_positions_better = reorganize_tag_positions(tag_positions)\n",
    "        \n",
    "    # Generate list of untagged text\n",
    "    lst_untagged_text = gen_lst_untagged(tag_positions_better, text)\n",
    "    \n",
    "    # Generate list of tagged and untagged text\n",
    "    lst_full_text = sorted(lst_tagged_text + lst_untagged_text, \n",
    "                           key = lambda x: x[1])\n",
    "    \n",
    "    # Add part-of-speech (POS) tags\n",
    "    for i, e in enumerate(lst_full_text):\n",
    "        tokens = nltk.word_tokenize(e[3])\n",
    "        pos_document = nltk.pos_tag(tokens)\n",
    "        lst_full_text[i][3] = pos_document\n",
    "    \n",
    "    # Generate table that stores info on what is going to be excluded from strings\n",
    "    table = str.maketrans({key: \" \" for key in set(string.punctuation + \n",
    "                                                   \"\\n\" + \"\\xa0\" + \n",
    "                                                   \"“\" + \"’\" + \"–\" + \n",
    "                                                   \"\\u201d\" + \"\\u2018\" + \"\\u2013\" + \"\\u2014\")})\n",
    "    \n",
    "    # Store English stop words\n",
    "    stopwords_en = stopwords.words('english')\n",
    "    \n",
    "    # Generate final list to be converted to tsv format (lemmatize on the way)\n",
    "    lst = []\n",
    "    for e in lst_full_text:\n",
    "        for token in e[3]:\n",
    "            # Remove punctuation, transform to lower case, and strip any white space at start/end\n",
    "            token = (token[0].translate(table).lower().strip(), token[1])\n",
    "            if token[0]:\n",
    "                if remove_stop_words:\n",
    "                    if token[0] not in stopwords_en:\n",
    "                        if focus:\n",
    "                            if e[0] == focus_word:\n",
    "                                if use_pos:\n",
    "                                    lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + token[1] + \"\\t\" + e[0]]\n",
    "                                else:\n",
    "                                    lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + e[0]]\n",
    "                            else:\n",
    "                                if use_pos:\n",
    "                                    lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + token[1] + \"\\t\" + 'O']\n",
    "                                else:\n",
    "                                    lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + 'O']\n",
    "                        else:\n",
    "                            if use_pos:\n",
    "                                lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + token[1] + \"\\t\" + e[0]]\n",
    "                            else:\n",
    "                                lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + e[0]]\n",
    "                else:\n",
    "                    if focus:\n",
    "                        if e[0] == focus_word:\n",
    "                            if use_pos:\n",
    "                                lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + token[1] + \"\\t\" + e[0]]\n",
    "                            else:\n",
    "                                lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + e[0]]\n",
    "                        else:\n",
    "                            if use_pos:\n",
    "                                lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + token[1] + \"\\t\" + 'O']\n",
    "                            else:\n",
    "                                lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + 'O']\n",
    "                    else:\n",
    "                        if use_pos:\n",
    "                            lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + token[1] + \"\\t\" + e[0]]\n",
    "                        else:\n",
    "                            lst += [lemmatizer.lemmatize(token[0]) + \"\\t\" + e[0]]\n",
    "    return(lst)\n",
    "\n",
    "def write_to_tsv(path_to_tsv, \n",
    "                 path_to_data, \n",
    "                 train_or_test, \n",
    "                 start_index,\n",
    "                 end_index,\n",
    "                 remove_stop_words = True, \n",
    "                 use_pos = True,\n",
    "                 focus = True, \n",
    "                 focus_word = \"Protester\"):\n",
    "    p = 0\n",
    "    with open(os.path.join(path_to_tsv, train_or_test), 'w') as file:        \n",
    "        for root, dirs, files in os.walk(path_to_data):\n",
    "            if not dirs and \"text.txt.gz\" in files and \"annotations.json.gz\" in files:\n",
    "                if start_index <= p and end_index > p:\n",
    "                    word_tag_lst = gen_word_tag_lst(root, remove_stop_words, use_pos, focus, focus_word)\n",
    "                    # Filter out Useless and ToBe tags\n",
    "                    word_tag_lst = list(filter(lambda x: 'Useless' not in x and 'ToBe' not in x, word_tag_lst))\n",
    "                    for e in word_tag_lst:\n",
    "                        file.write(e + '\\n')\n",
    "                    if word_tag_lst:\n",
    "                        file.write('\\n')\n",
    "                p += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_data_2017 = \"./DocumentsParsed-2017\"\n",
    "path_to_data = \"./df-corpus\"\n",
    "\n",
    "path_to_tsv = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train data\n",
    "write_to_tsv(path_to_tsv, path_to_data, train_or_test = 'train.tsv', \n",
    "             start_index = 0, end_index = 500,\n",
    "             remove_stop_words = True, use_pos = True, focus = False, focus_word = \"Protester\")\n",
    "\n",
    "# Generate test data\n",
    "write_to_tsv(path_to_tsv, path_to_data, train_or_test = 'test.tsv', \n",
    "             start_index = 500, end_index = 600,\n",
    "             remove_stop_words = True, use_pos = True, focus = False, focus_word = \"Protester\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - Invoked on Sun Mar 03 01:28:27 UTC 2019 with arguments: -prop ./df-classifier.prop\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - useWordTag=true\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - serializeTo=./custom-tagger.ser.gz\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - trainFile=./train.tsv\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - map=word=0,tag=1,answer=2\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - numFeatures = 93937\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - Time to convert docs to feature indices: 1.5 seconds\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - numClasses: 9 [0=O,1=Info,2=Opinionor,3=Protester,4=Camp,5=Legal_Action,6=Strategy,7=Government,8=Police]\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - numDocuments: 499\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - numDatums: 121957\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - numFeatures: 93937\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - Time to convert docs to data/labels: 1.0 seconds\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - numWeights: 845433\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - QNMinimizer called on double function of 845433 variables, using M = 25.\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -                An explanation of the output:\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter           The number of iterations\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - evals          The number of function evaluations\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - LINESEARCH     [## M steplength]  Minpack linesearch\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -                    1-Function value was too high\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -                    2-Value ok, gradient positive, positive curvature\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -                    3-Value ok, gradient negative, positive curvature\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -                    4-Value ok, gradient negative, negative curvature\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -                [.. B]  Backtracking\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - VALUE          The current function value\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - TIME           Total elapsed time\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - |GNORM|        The current norm of the gradient\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - {RELNORM}      The ratio of the current to initial gradient norms\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - AVEIMPROVE     The average improvement / current value\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - EVALSCORE      The last available eval score\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer -  \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE\n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 1 evals 1 <D> [113M 4.085E-3] 4.103E5 22.43s |3.080E3| {1.110E0} 0.000E0 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 2 evals 5 <D> [M 1.000E0] 4.070E5 27.62s |3.632E3| {1.309E0} 4.020E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 3 evals 6 <D> [M 1.000E0] 3.937E5 32.62s |3.384E3| {1.220E0} 1.405E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 4 evals 7 <D> [M 1.000E0] 3.778E5 37.62s |3.018E3| {1.088E0} 2.145E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 5 evals 8 <D> [M 1.000E0] 3.699E5 42.64s |2.815E3| {1.015E0} 2.182E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 6 evals 9 <D> [M 1.000E0] 3.612E5 47.87s |3.446E3| {1.242E0} 2.265E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 7 evals 10 <D> [M 1.000E0] 3.514E5 52.87s |2.848E3| {1.027E0} 2.395E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 8 evals 11 <D> [M 1.000E0] 3.401E5 57.92s |1.895E3| {6.832E-1} 2.578E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 9 evals 12 <D> [M 1.000E0] 3.312E5 62.97s |2.832E3| {1.021E0} 2.652E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 10 evals 13 <D> [M 1.000E0] 3.221E5 68.00s |3.158E3| {1.139E0} 2.738E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 11 evals 14 <D> [M 1.000E0] 3.100E5 73.01s |2.299E3| {8.289E-1} 3.127E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 12 evals 15 <D> [M 1.000E0] 2.995E5 78.10s |2.568E3| {9.258E-1} 3.143E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 13 evals 16 <D> [M 1.000E0] 2.893E5 83.08s |2.260E3| {8.147E-1} 3.060E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 14 evals 17 <D> [M 1.000E0] 2.837E5 88.16s |4.212E3| {1.518E0} 3.037E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 15 evals 18 <D> [M 1.000E0] 2.719E5 93.19s |3.537E3| {1.275E0} 3.281E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 16 evals 19 <D> [M 1.000E0] 2.616E5 98.22s |2.208E3| {7.961E-1} 3.433E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 17 evals 20 <D> [M 1.000E0] 2.540E5 103.25s |1.884E3| {6.790E-1} 3.389E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 18 evals 21 <D> [M 1.000E0] 2.423E5 108.23s |2.113E3| {7.615E-1} 3.668E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 19 evals 22 <D> [M 1.000E0] 2.365E5 113.30s |3.017E3| {1.088E0} 3.620E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 20 evals 23 <D> [M 1.000E0] 2.290E5 118.44s |2.667E3| {9.615E-1} 3.541E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 21 evals 24 <D> [M 1.000E0] 2.219E5 123.51s |2.016E3| {7.269E-1} 3.496E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 22 evals 25 <D> [M 1.000E0] 2.164E5 128.72s |1.596E3| {5.752E-1} 3.372E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 23 evals 26 <D> [M 1.000E0] 2.125E5 134.23s |2.359E3| {8.504E-1} 3.351E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 24 evals 27 <D> [M 1.000E0] 2.080E5 139.29s |1.834E3| {6.610E-1} 3.074E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 25 evals 28 <D> [M 1.000E0] 2.039E5 144.40s |1.181E3| {4.256E-1} 2.828E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 26 evals 29 <D> [M 1.000E0] 2.007E5 149.53s |1.578E3| {5.690E-1} 2.657E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 27 evals 30 <D> [M 1.000E0] 1.971E5 154.64s |1.157E3| {4.171E-1} 2.293E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 28 evals 31 <D> [M 1.000E0] 1.931E5 159.70s |1.245E3| {4.489E-1} 2.244E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 29 evals 32 <D> [M 1.000E0] 1.908E5 164.79s |1.561E3| {5.629E-1} 2.000E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 30 evals 33 <D> [M 1.000E0] 1.880E5 169.91s |1.091E3| {3.932E-1} 1.808E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 31 evals 34 <D> [M 1.000E0] 1.860E5 175.08s |8.223E2| {2.964E-1} 1.634E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 32 evals 35 <D> [M 1.000E0] 1.839E5 180.30s |1.173E3| {4.230E-1} 1.557E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 33 evals 36 <D> [M 1.000E0] 1.820E5 185.43s |1.000E3| {3.605E-1} 1.431E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 34 evals 37 <D> [M 1.000E0] 1.805E5 190.56s |6.568E2| {2.368E-1} 1.299E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 35 evals 38 <D> [M 1.000E0] 1.791E5 195.76s |6.176E2| {2.227E-1} 1.207E-2 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 36 evals 39 <D> [M 1.000E0] 1.781E5 200.88s |8.169E2| {2.945E-1} 1.070E-2 - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 37 evals 40 <D> [M 1.000E0] 1.770E5 206.04s |4.952E2| {1.785E-1} 9.109E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 38 evals 41 <D> [M 1.000E0] 1.760E5 211.21s |4.593E2| {1.656E-1} 8.386E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 39 evals 42 <D> [M 1.000E0] 1.755E5 216.40s |8.367E2| {3.016E-1} 7.096E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 40 evals 43 <D> [M 1.000E0] 1.747E5 221.55s |4.735E2| {1.707E-1} 6.457E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 41 evals 44 <D> [M 1.000E0] 1.744E5 226.67s |5.202E2| {1.875E-1} 5.446E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 42 evals 45 <D> [M 1.000E0] 1.740E5 231.81s |2.328E2| {8.393E-2} 4.591E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 43 evals 46 <D> [M 1.000E0] 1.736E5 236.94s |3.146E2| {1.134E-1} 3.979E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 44 evals 47 <D> [M 1.000E0] 1.734E5 242.07s |3.598E2| {1.297E-1} 3.302E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 45 evals 48 <D> [M 1.000E0] 1.731E5 247.22s |2.167E2| {7.811E-2} 2.848E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 46 evals 49 <D> [M 1.000E0] 1.730E5 252.36s |2.229E2| {8.037E-2} 2.328E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 47 evals 50 <D> [M 1.000E0] 1.729E5 257.45s |1.901E2| {6.853E-2} 1.845E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 48 evals 51 <D> [M 1.000E0] 1.728E5 262.60s |1.398E2| {5.040E-2} 1.588E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 49 evals 52 <D> [M 1.000E0] 1.727E5 267.73s |1.637E2| {5.901E-2} 1.162E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 50 evals 53 <D> [M 1.000E0] 1.726E5 272.89s |1.162E2| {4.189E-2} 1.018E-3 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 51 evals 54 <D> [M 1.000E0] 1.726E5 278.05s |1.608E2| {5.795E-2} 8.030E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 52 evals 55 <D> [M 1.000E0] 1.725E5 283.16s |6.711E1| {2.419E-2} 5.896E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 53 evals 56 <D> [M 1.000E0] 1.725E5 288.31s |8.659E1| {3.122E-2} 4.831E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 54 evals 57 <D> [M 1.000E0] 1.725E5 293.50s |1.129E2| {4.071E-2} 3.782E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 55 evals 58 <D> [M 1.000E0] 1.725E5 298.62s |9.754E1| {3.516E-2} 2.926E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 56 evals 59 <D> [M 1.000E0] 1.725E5 303.80s |5.073E1| {1.829E-2} 2.282E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 57 evals 60 <D> [M 1.000E0] 1.724E5 309.02s |5.784E1| {2.085E-2} 1.833E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 58 evals 61 <D> [M 1.000E0] 1.724E5 314.14s |5.831E1| {2.102E-2} 1.458E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Iter 59 evals 62 <D> [M 1.000E0] 1.724E5 319.28s |5.402E1| {1.948E-2} 1.139E-4 - \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - QNMinimizer terminated due to average improvement: | newest_val - previous_val | / |newestVal| < TOL \n",
      "[main] INFO edu.stanford.nlp.optimization.QNMinimizer - Total time spent in optimization: 324.40s\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - CRFClassifier training ... done [333.4 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - Serializing classifier to ./custom-tagger.ser.gz... done.\n",
      "5.620261820157369\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train model\n",
    "\n",
    "!java -Xmx16g -cp \"./stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.ie.crf.CRFClassifier \\\n",
    "-prop ./df-classifier.prop\n",
    "\n",
    "print((time.time()-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.ie.crf.CRFClassifier - Invoked on Sun Mar 03 02:02:49 UTC 2019 with arguments: -loadClassifier ./custom-tagger.ser.gz -testFile ./test.tsv -outputFormat tsv\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - testFile=./test.tsv\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - loadClassifier=./custom-tagger.ser.gz\n",
      "[main] INFO edu.stanford.nlp.sequences.SeqClassifierFlags - outputFormat=tsv\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from ./custom-tagger.ser.gz ... done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - CRFClassifier tagged 23289 words in 100 documents at 1696.21 words per second.\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -          Entity\tP\tR\tF1\tTP\tFP\tFN\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -            Camp\t0.0010\t0.0077\t0.0017\t2\t2025\t257\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -      Government\t0.0017\t0.0102\t0.0030\t1\t574\t97\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -            Info\t0.0000\t0.0000\t0.0000\t0\t239\t29\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -    Legal_Action\t0.0000\t0.0000\t0.0000\t0\t556\t86\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -       Opinionor\t0.0006\t0.0085\t0.0011\t1\t1742\t116\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -          Police\t0.0000\t0.0000\t0.0000\t0\t862\t98\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -       Protester\t0.0024\t0.0309\t0.0045\t5\t2059\t157\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -        Strategy\t0.0000\t0.0000\t0.0000\t0\t2120\t194\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier -          Totals\t0.0009\t0.0086\t0.0016\t9\t10177\t1034\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "\n",
    "!java -Xmx16g -cp \"./stanford-corenlp-full-2018-10-05/*\" edu.stanford.nlp.ie.crf.CRFClassifier \\\n",
    "-loadClassifier ./custom-tagger.ser.gz -testFile ./test.tsv \\\n",
    "-outputFormat tsv 1> \"./test-results/0-500-500-600-RP-ULC-L-RSW-UPOS-DNF-NA.tsv\"\n",
    "\n",
    "# num1: train start\n",
    "# num2: train end\n",
    "# num3: test start\n",
    "# num4: test end\n",
    "\n",
    "# RP: remove punctuation\n",
    "# DNRP: do not remove punctuation\n",
    "\n",
    "# ULC: use lower case\n",
    "# DNULC: do not use lower case\n",
    "\n",
    "# L: lemmatize\n",
    "# DNL: do not lemmatize\n",
    "\n",
    "# RSW: remove stop words\n",
    "# DNRSW: do not remove stop words\n",
    "\n",
    "# UPOS: use part-of-speech\n",
    "# DNUPOS: do not use part-of-speech\n",
    "\n",
    "# F: focus\n",
    "# DNF: do not focus\n",
    "\n",
    "# Pr: Protester\n",
    "# O: Opinioner\n",
    "# C: Camp\n",
    "# S: Strategy\n",
    "# I: Info\n",
    "# G: Government\n",
    "# P: Police\n",
    "# L: Legal_Action\n",
    "# NA: not applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP, FP, TN, FN for O are: [4409, 6233, 3214, 3114]\n",
      "Accuracy for O is: 0.4492044784914555\n",
      "Precision for O is: 0.41430182296560797\n",
      "Recall for O is: 0.5860693872125482\n",
      "Specificity for O is: 0.3402138244945485\n",
      "F1 score for O is: 0.485439031103771\n",
      "\n",
      "TP, FP, TN, FN for Protester are: [666, 2047, 6957, 1601]\n",
      "Accuracy for Protester is: 0.6763375033271227\n",
      "Precision for Protester is: 0.2454847032805013\n",
      "Recall for Protester is: 0.2937803264225849\n",
      "Specificity for Protester is: 0.7726565970679697\n",
      "F1 score for Protester is: 0.2674698795180723\n",
      "\n",
      "TP, FP, TN, FN for Opinionor are: [741, 1601, 6882, 1730]\n",
      "Accuracy for Opinionor is: 0.695910169800986\n",
      "Precision for Opinionor is: 0.31639624252775406\n",
      "Recall for Opinionor is: 0.2998785916632942\n",
      "Specificity for Opinionor is: 0.8112695980195685\n",
      "F1 score for Opinionor is: 0.30791606066902144\n",
      "\n",
      "TP, FP, TN, FN for Camp are: [688, 1835, 6935, 2727]\n",
      "Accuracy for Camp is: 0.6256052523594583\n",
      "Precision for Camp is: 0.27269124058660327\n",
      "Recall for Camp is: 0.20146412884333822\n",
      "Specificity for Camp is: 0.7907639680729761\n",
      "F1 score for Camp is: 0.23172785449646346\n",
      "\n",
      "TP, FP, TN, FN for Strategy are: [624, 1952, 6999, 2564]\n",
      "Accuracy for Strategy is: 0.6279759453002719\n",
      "Precision for Strategy is: 0.2422360248447205\n",
      "Recall for Strategy is: 0.19573400250941028\n",
      "Specificity for Strategy is: 0.7819238073958217\n",
      "F1 score for Strategy is: 0.21651630811936157\n",
      "\n",
      "TP, FP, TN, FN for Info are: [27, 222, 7596, 446]\n",
      "Accuracy for Info is: 0.9194307079966229\n",
      "Precision for Info is: 0.10843373493975904\n",
      "Recall for Info is: 0.05708245243128964\n",
      "Specificity for Info is: 0.9716039907904835\n",
      "F1 score for Info is: 0.07479224376731303\n",
      "\n",
      "TP, FP, TN, FN for Government are: [126, 508, 7497, 954]\n",
      "Accuracy for Government is: 0.8390753990093561\n",
      "Precision for Government is: 0.19873817034700317\n",
      "Recall for Government is: 0.11666666666666667\n",
      "Specificity for Government is: 0.9365396627108058\n",
      "F1 score for Government is: 0.14702450408401402\n",
      "\n",
      "TP, FP, TN, FN for Police are: [258, 756, 7365, 1234]\n",
      "Accuracy for Police is: 0.7929886611879746\n",
      "Precision for Police is: 0.25443786982248523\n",
      "Recall for Police is: 0.17292225201072386\n",
      "Specificity for Police is: 0.9069080162541558\n",
      "F1 score for Police is: 0.20590582601755789\n",
      "\n",
      "TP, FP, TN, FN for Legal_Action are: [84, 512, 7539, 1296]\n",
      "Accuracy for Legal_Action is: 0.8082918036263387\n",
      "Precision for Legal_Action is: 0.14093959731543623\n",
      "Recall for Legal_Action is: 0.06086956521739131\n",
      "Specificity for Legal_Action is: 0.9364054154763384\n",
      "F1 score for Legal_Action is: 0.08502024291497975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./test-results/0-500-500-600-RP-ULC-L-RSW-UPOS-DNF-NA.tsv\", \n",
    "                 sep = '\\t',\n",
    "                 names = [\"word\", \"obs\", \"pred\"])\n",
    "\n",
    "#                      TP, FP, TN, FN\n",
    "d = {\"O\"            : [0,  0,  0,  0],\n",
    "     \"Protester\"    : [0,  0,  0,  0],\n",
    "     \"Opinionor\"    : [0,  0,  0,  0],\n",
    "     \"Camp\"         : [0,  0,  0,  0],\n",
    "     \"Strategy\"     : [0,  0,  0,  0],\n",
    "     \"Info\"         : [0,  0,  0,  0],\n",
    "     \"Government\"   : [0,  0,  0,  0],\n",
    "     \"Police\"       : [0,  0,  0,  0],\n",
    "     \"Legal_Action\" : [0,  0,  0,  0]}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['obs'] == row['pred']:\n",
    "        d[row['pred']][0] += 1\n",
    "        for key in d.keys():\n",
    "            if key != row['pred']:\n",
    "                d[key][2] += 1\n",
    "    if row['obs'] != row['pred']:\n",
    "        d[row['pred']][1] += 1\n",
    "        d[row['obs']][3] += 1\n",
    "\n",
    "for key in d.keys():\n",
    "    if d[key][0] == 0 and d[key][1] == 0 and d[key][3] == 0:\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            accuracy     = (d[key][0] + d[key][2])/sum(d[key])\n",
    "        except:\n",
    "            accuracy     = 0\n",
    "        try:\n",
    "            precision    = d[key][0]/(d[key][0] + d[key][1])\n",
    "        except:\n",
    "            precision    = 0\n",
    "        try:\n",
    "            recall       = d[key][0]/(d[key][0] + d[key][3])\n",
    "        except: \n",
    "            recal        = 0\n",
    "        try:\n",
    "            specificity  = d[key][2]/(d[key][1] + d[key][2])\n",
    "        except:\n",
    "            specificity  = 0\n",
    "        try:\n",
    "            f1_score     = 2*precision*recall/(precision+recall)\n",
    "        except:\n",
    "            f1_score     = 0\n",
    "\n",
    "        print(\"TP, FP, TN, FN for \" + key + \" are: \" + str(d[key]))\n",
    "        print(\"Accuracy for \"       + key + \" is: \"  + str(accuracy))\n",
    "        print(\"Precision for \"      + key + \" is: \"  + str(precision))\n",
    "        print(\"Recall for \"         + key + \" is: \"  + str(recall))\n",
    "        print(\"Specificity for \"    + key + \" is: \"  + str(specificity))\n",
    "        print(\"F1 score for \"       + key + \" is: \"  + str(f1_score) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Count number of articles in the corpus\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(\"./df-corpus\"):\n",
    "        if not dirs and \"text.txt.gz\" in files and \"annotations.json.gz\" in files:\n",
    "            count += 1\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # The slicing in the first for loop can be used \n",
    "    #   to select only those directories from a specific city (e.g., 0:11 is Albany)\n",
    "    # The slicing in the second for loop can be used \n",
    "    #   to select the number of articles from that specific city.\n",
    "    #   This is relevant when splitting articles from a specific city\n",
    "    #   into train and test batches. \n",
    "    def write_to_tsv_alt(path_to_tsv, \n",
    "                         path_to_data, \n",
    "                         train_or_test, \n",
    "                         start1 = 0,\n",
    "                         end1 = 1342,\n",
    "                         start2 = 0,\n",
    "                         end2 = None,\n",
    "                         remove_stop_words = True, \n",
    "                         focus = True, \n",
    "                         focus_word = \"Protester\", \n",
    "                         use_pos = True):\n",
    "        with open(os.path.join(path_to_tsv, train_or_test), 'w') as file:\n",
    "            for f in sorted(os.listdir(path_to_data))[start1:end1]:\n",
    "                if f != \".DS_Store\":\n",
    "                    for sf in sorted(os.listdir(os.path.join(path_to_data, f)))[start2:end2]:\n",
    "                        if sf != \".DS_Store\":\n",
    "                            path = os.path.join(path_to_data, f, sf)\n",
    "                            word_tag_lst = gen_word_tag_lst(path, remove_stop_words, focus, focus_word, use_pos)\n",
    "                            # Filter out Useless and ToBe tags\n",
    "                            word_tag_lst = list(\n",
    "                                filter(lambda x: 'Useless' not in x and 'ToBe' not in x, word_tag_lst))\n",
    "                            for e in word_tag_lst:\n",
    "                                file.write(e + '\\n')\n",
    "                            if word_tag_lst:\n",
    "                                file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # The slicing in the first for loop can be used \n",
    "    #   to select only those directories from a specific city (e.g., 0:11 is Albany)\n",
    "    # The slicing in the second for loop can be used \n",
    "    #   to select the number of articles from that specific city.\n",
    "    #   This is relevant when splitting articles from a specific city\n",
    "    #   into train and test batches. \n",
    "    count = 0\n",
    "    for f in sorted(os.listdir(path_to_data))[0:11]:\n",
    "        if f != \".DS_Store\":\n",
    "            for sf in sorted(os.listdir(os.path.join(path_to_data, f)))[0:]:\n",
    "                if sf != \".DS_Store\":\n",
    "                    path = os.path.join(path_to_data, f, sf)\n",
    "                    print(path)\n",
    "                    count += 1\n",
    "    print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
